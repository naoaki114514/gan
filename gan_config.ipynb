{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda:0\ntorch.Size([64, 100, 1, 1])\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n   ConvTranspose2d-1            [-1, 512, 4, 4]         819,200\n       BatchNorm2d-2            [-1, 512, 4, 4]           1,024\n         LeakyReLU-3            [-1, 512, 4, 4]               0\n   ConvTranspose2d-4            [-1, 256, 8, 8]       2,097,152\n       BatchNorm2d-5            [-1, 256, 8, 8]             512\n         LeakyReLU-6            [-1, 256, 8, 8]               0\n   ConvTranspose2d-7          [-1, 128, 16, 16]         524,288\n       BatchNorm2d-8          [-1, 128, 16, 16]             256\n         LeakyReLU-9          [-1, 128, 16, 16]               0\n  ConvTranspose2d-10           [-1, 64, 32, 32]         131,072\n      BatchNorm2d-11           [-1, 64, 32, 32]             128\n        LeakyReLU-12           [-1, 64, 32, 32]               0\n  ConvTranspose2d-13            [-1, 3, 64, 64]           3,072\n             Tanh-14            [-1, 3, 64, 64]               0\n================================================================\nTotal params: 3,576,704\nTrainable params: 3,576,704\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 3.00\nParams size (MB): 13.64\nEstimated Total Size (MB): 16.64\n----------------------------------------------------------------\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           3,072\n         LeakyReLU-2           [-1, 64, 32, 32]               0\n           Dropout-3           [-1, 64, 32, 32]               0\n            Conv2d-4          [-1, 128, 16, 16]         131,072\n       BatchNorm2d-5          [-1, 128, 16, 16]             256\n         LeakyReLU-6          [-1, 128, 16, 16]               0\n           Dropout-7          [-1, 128, 16, 16]               0\n            Conv2d-8            [-1, 256, 8, 8]         524,288\n       BatchNorm2d-9            [-1, 256, 8, 8]             512\n        LeakyReLU-10            [-1, 256, 8, 8]               0\n          Dropout-11            [-1, 256, 8, 8]               0\n           Conv2d-12            [-1, 512, 4, 4]       2,097,152\n      BatchNorm2d-13            [-1, 512, 4, 4]           1,024\n        LeakyReLU-14            [-1, 512, 4, 4]               0\n          Dropout-15            [-1, 512, 4, 4]               0\n           Conv2d-16              [-1, 1, 1, 1]           8,192\n          Sigmoid-17              [-1, 1, 1, 1]               0\n================================================================\nTotal params: 2,765,568\nTrainable params: 2,765,568\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.05\nForward/backward pass size (MB): 3.25\nParams size (MB): 10.55\nEstimated Total Size (MB): 13.85\n----------------------------------------------------------------\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torchvision.utils as vutils\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "batch_size = 64 #一度に学習するデータ量\n",
    "nz = 100#random noisze z 潜在変数の次元\n",
    "nc = 3\n",
    "\n",
    "class Generator(nn.Module):\n",
    "  def __init__(self, nz):\n",
    "    super(Generator, self).__init__()\n",
    "    self.nz = nz\n",
    "    self.nf = 64\n",
    "    self.main = nn.Sequential(\n",
    "        nn.ConvTranspose2d(self.nz, self.nf * 8, 4, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(self.nf * 8),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.ConvTranspose2d(self.nf * 8, self.nf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(self.nf * 4),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.ConvTranspose2d(self.nf * 4, self.nf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(self.nf * 2),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.ConvTranspose2d(self.nf * 2, self.nf, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(self.nf),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.ConvTranspose2d(self.nf, nc, 4, 2, 1, bias=False),\n",
    "        nn.Tanh() \n",
    "        #nn.Sigmoid()\n",
    "\n",
    "    )\n",
    "  def forward(self, input):\n",
    "    output = self.main(input)\n",
    "    return output\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.nf = 64\n",
    "    self.main = nn.Sequential(\n",
    "        nn.Conv2d(nc, self.nf, 4, 2, 1, bias = False),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Conv2d(self.nf, self.nf * 2, 4, 2, 1, bias = False),\n",
    "        nn.BatchNorm2d(self.nf * 2),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Conv2d(self.nf * 2, self.nf * 4, 4, 2, 1, bias = False),\n",
    "        nn.BatchNorm2d(self.nf * 4),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Conv2d(self.nf * 4, self.nf * 8, 4, 2, 1, bias = False),\n",
    "        nn.BatchNorm2d(self.nf * 8),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Conv2d(self.nf * 8, 1, 4, 1, 0, bias = False),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "  def forward(self, input):\n",
    "    output = self.main(input)\n",
    "    return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "\n",
    "netG = Generator(nz).to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "summary(netG, (nz, 1, 1))#batch sizeはいらない 入力は(C,H,W)\n",
    "\n",
    "summary(netD, (3, 64, 64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594555958459",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}